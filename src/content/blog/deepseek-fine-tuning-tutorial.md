---
title: "é›¶åŸºç¡€å…¥é—¨ï¼šDeepSeekå¾®è°ƒæ•™ç¨‹æ¥äº†ï¼"
description: "é›¶åŸºç¡€å…¥é—¨ï¼šDeepSeekå¤§æ¨¡å‹å¾®è°ƒå®ç”¨æ•™ç¨‹ï¼"
pubDate: "2025-02-25 14:53:30"
tags: ["DeepSeek", "LLM", "å¾®è°ƒ", " AI"]
categories: ["AI"]
---

> å¼€å§‹ä¹‹å‰ï¼Œè®°å¾—å…è´¹é¢†å–ç«å±±å¼•æ“ DeekSeek  R1 æ»¡è¡€ç‰ˆï¼Œé€Ÿåº¦æå¿«ã€‚ 
>  [ç‚¹æ­¤ç«‹å³é¢†å–](https://www.volcengine.com/experience/ark?utm_term=202502dsinvite&ac=DSASUQY5&rc=ZEWLRBY9)

å¼€é—¨è§å±±ï¼Œç›´æ¥ç»™å¤§å®¶å±•ç¤ºå¾®è°ƒå‰åçš„æ•ˆæœã€‚

å¾®è°ƒå‰ï¼š

![img.png](../attachments/1/img.png)

å¾®è°ƒåï¼š

![img_1.png](../attachments/1/img_1.png)

åœ¨æ­¤å¤„å¯ä»¥çœ‹åˆ°å¾ˆæ˜æ˜¾å¤§æ¨¡å‹è¿›è¡Œå¾®è°ƒåå£å»å·²ç»å‘ç”Ÿäº†æ›´æ”¹ã€‚æ®ç¬”è€…ä½¿ç”¨ä¸‹æ¥çš„è®°å½•è¡¨ç¤ºï¼Œå¾®è°ƒåçš„å¤§æ¨¡å‹æ€è€ƒæ—¶é—´æ›´åŠ çŸ­æš‚ã€‚

æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬ä¸€èµ·é€æ­¥å®Œæˆå¾®è°ƒå®è·µï¼Œå…±åŒä¼˜åŒ–æ¨¡å‹æ€§èƒ½ï¼

## ä¸€ã€ä»€ä¹ˆæ˜¯å¤§æ¨¡å‹å¾®è°ƒï¼Ÿ

å¾®è°ƒå°±åƒç»™ä¸€ä¸ªâ€œå­¦éœ¸â€è¡¥è¯¾ï¼Œè®©å®ƒä»â€œé€šæ‰â€å˜æˆæŸä¸ªé¢†åŸŸçš„â€œä¸“å®¶â€ã€‚

æ­¤å¤„ä»¥æœ¬æ–‡è¿›è¡Œå¾®è°ƒçš„åŒ»å­¦æ•°æ®è¿›è¡Œä¸¾ä¾‹ï¼š å‡è®¾ä½ æœ‰ä¸€ä¸ªå¾ˆèªæ˜çš„æœ‹å‹ï¼Œä»–è¯»è¿‡å…¨ä¸–ç•Œçš„ä¹¦ï¼ˆç›¸å½“äºå¤§æ¨¡å‹çš„é¢„è®­ç»ƒé˜¶æ®µï¼‰ï¼Œèƒ½å’Œä½ èŠå†å²ã€ç§‘å­¦ã€æ–‡å­¦ç­‰å„ç§è¯é¢˜ã€‚ ä½†å¦‚æœä½ éœ€è¦ä»–å¸®ä½ çœ‹åŒ»å­¦æŠ¥å‘Šæ®µï¼‰ï¼Œèƒ½å’Œä½ èŠå†å²ã€ç§‘å­¦ã€æ–‡å­¦ç­‰å„ç§è¯é¢˜ã€‚ ä½†å¦‚æœä½ éœ€è¦ä»–å¸®ä½ çœ‹åŒ»å­¦æŠ¥å‘Šï¼Œè™½ç„¶ä»–æ‡‚ä¸€äº›åŸºç¡€çŸ¥è¯†ï¼Œä½†å¯èƒ½ä¸å¤Ÿä¸“ä¸šã€‚è¿™æ—¶å€™ï¼Œä½ ç»™ä»–ä¸€å †åŒ»å­¦ä¹¦ç±å’Œç—…ä¾‹ï¼Œè®©ä»–ä¸“é—¨å­¦ä¹ è¿™æ–¹é¢çš„çŸ¥è¯†ï¼ˆè¿™å°±æ˜¯å¾®è°ƒï¼‰ï¼Œä»–å°±ä¼šå˜å¾—æ›´æ“…é•¿åŒ»ç–—é¢†åŸŸçš„é—®é¢˜ã€‚

### ğŸ“– æ•…äº‹è§£é‡Šï¼š
æƒ³è±¡ä½ æœ‰ä¸€ä¸ªä¼šç”»å°çŒ«çš„æœºå™¨äººğŸ¤–ï¼ˆè¿™å°±æ˜¯é¢„è®­ç»ƒæ¨¡å‹ï¼‰ã€‚ç°åœ¨ä½ æƒ³è®©å®ƒå­¦ä¼šç”»æˆ´å¸½å­çš„å°çŒ«ğŸ©ğŸ±ã€‚ä¸éœ€è¦ä»å¤´æ•™å®ƒç”»ç”»ï¼Œåªéœ€è¦ç»™å®ƒçœ‹å¾ˆå¤š"æˆ´å¸½å­å°çŒ«"çš„å›¾ç‰‡ï¼Œç„¶åè¯´ï¼š"ä¿æŒåŸæ¥çš„ç”»ç”»èƒ½åŠ›ï¼Œä½†è¦å­¦ä¼šåŠ å¸½å­å“¦ï¼" è¿™å°±æ˜¯å¾®è°ƒï¼

### ğŸ“– ç”Ÿæ´»æ¡ˆä¾‹è§£é‡Šï¼š
#### æ¡ˆä¾‹1ï¼šæ™ºèƒ½éŸ³ç®±è°ƒæ–¹è¨€
- åŸºç¡€ç‰ˆéŸ³ç®±åªä¼šæ™®é€šè¯ï¼ˆé¢„è®­ç»ƒæ¨¡å‹ï¼‰

- ç»™å®ƒå¬ 100 å¥å››å·è¯ï¼ˆå¾®è°ƒæ•°æ®ï¼‰

- ç°åœ¨èƒ½å¬æ‡‚"æ‘†é¾™é—¨é˜µ"ï¼ˆæ–¹è¨€ç†è§£èƒ½åŠ›â†‘ï¼‰

#### æ¡ˆä¾‹2ï¼šç›¸æœºæ»¤é•œåŸç†
- åŸå§‹ç›¸æœºæ‹æ‰€æœ‰åœºæ™¯ï¼ˆé€šç”¨æ¨¡å‹ï¼‰

- åŠ è½½â€œç¾é£Ÿæ»¤é•œâ€å‚æ•°ï¼ˆå¾®è°ƒåçš„æ¨¡å‹ï¼‰

- æ‹é£Ÿç‰©æ—¶è‡ªåŠ¨å¢å¼ºé¥±å’Œåº¦ï¼ˆä¸“ä¸šèƒ½åŠ›å¼ºåŒ–ï¼‰

### åŠ å¼ºç‰ˆè§£é‡Šï¼šä¹é«˜åŸå ¡æ”¹é€ æˆå„¿ç«¥åŒ»é™¢

##### ç¬¬ä¸€æ­¥ï¼šåŸæœ‰ç»“æ„ â€”â€” é€šç”¨ä¹é«˜åŸå ¡
[é€šç”¨åŸå ¡]

â–¸ æ¯”å–»ï¼šå°±åƒç½‘è´­çš„"æ ‡å‡†æ¬¾åŸå ¡ç§¯æœ¨å¥—è£…"ï¼Œæœ‰åŸå¢™ã€å¡”æ¥¼ã€å°–é¡¶ï¼Œèƒ½å½“æ™®é€šæˆ¿å­ç”¨ã€‚

â–¸ å¯¹åº”æŠ€æœ¯ï¼šé¢„è®­ç»ƒæ¨¡å‹ï¼ˆæ¯”å¦‚ ChatGPTï¼‰ï¼Œå·²ç»å­¦ä¼šé€šç”¨è¯­è¨€èƒ½åŠ›ï¼Œä½†ä¸å¤Ÿä¸“ä¸šã€‚

##### ç¬¬äºŒæ­¥ï¼šå±€éƒ¨æ”¹é€  â€”â€” ä½æˆæœ¬æ”¹è£…
> â‘  æ‹†å°–é¡¶ â†’ æ”¹åœ†é¡¶

[å°–é¡¶æ”¹åœ†é¡¶]

â–¸ æ“ä½œï¼šæŠŠå¡”é¡¶çš„å°–ç§¯æœ¨æ¢æˆåœ†ç§¯æœ¨ï¼Œæ›´æ¸©å’Œå¯çˆ±ã€‚

â–¸ æŠ€æœ¯å«ä¹‰ï¼šå¾®è°ƒæ¨¡å‹é¡¶å±‚å‚æ•°ï¼ˆæ¯”å¦‚ä¿®æ”¹åˆ†ç±»å¤´ï¼‰ï¼Œè®©è¾“å‡ºé£æ ¼æ›´é€‚åˆå„¿ç«¥å¯¹è¯ã€‚

> â‘¡ åŠ è£…æ—‹è½¬é—¨[æ—‹è½¬é—¨]

â–¸ æ“ä½œï¼šåœ¨é—¨å£æ’å…¥ä¸€ä¸ªå¯æ—‹è½¬çš„ç§¯æœ¨æ¨¡å—ï¼Œä¸ç ´ååŸæœ‰é—¨ç»“æ„ã€‚

â–¸ æŠ€æœ¯å«ä¹‰ï¼šæ’å…¥é€‚é…å™¨æ¨¡å—ï¼ˆAdapterï¼‰ï¼Œè®©æ¨¡å‹æ–°å¢å„¿ç§‘åŒ»å­¦æœ¯è¯­ç†è§£èƒ½åŠ›ï¼Œä¸”ä¸å¹²æ‰°åŸæœ‰çŸ¥è¯†ã€‚

> â‘¢ æ¶‚è£…åŒ»é™¢æ ‡å¿—

[åŒ»é™¢æ ‡å¿—]

â–¸ æ“ä½œï¼šåœ¨åŸå ¡å¤–å¢™è´´ä¸Š"åå­—ç¬¦å·"å’Œå¡é€šåŠ¨ç‰©è´´çº¸ã€‚

â–¸ æŠ€æœ¯å«ä¹‰ï¼šç‰¹å¾ç©ºé—´åç§»ï¼ˆFeature Shiftï¼‰ï¼Œè°ƒæ•´æ¨¡å‹å†…éƒ¨è¡¨ç¤ºï¼Œè®©å®ƒæ›´å…³æ³¨åŒ»ç–—ç›¸å…³è¯æ±‡å’Œç«¥è¶£è¡¨è¾¾ã€‚

##### ç¬¬ä¸‰æ­¥ï¼šæ–°åŠŸèƒ½ â€”â€” å˜èº«å„¿ç«¥åŒ»é™¢

[å„¿ç«¥åŒ»é™¢]

â–¸ æˆæœï¼šæ”¹è£…åçš„åŸå ¡èƒ½æ¥å¾…å°æ‚£è€…ï¼Œæœ‰ç©å…·åŒºã€æ¸©å’Œçš„åŒ»ç”Ÿï¼ˆåœ†é¡¶ï¼‰ï¼Œè¿˜æœ‰ä¸“ç”¨åŒ»ç–—è®¾å¤‡ï¼ˆæ—‹è½¬é—¨ï¼‰ã€‚

â–¸ æŠ€æœ¯å«ä¹‰ï¼šé€šè¿‡è½»é‡æ”¹é€ ï¼Œé€šç”¨æ¨¡å‹å˜æˆ"å„¿ç§‘åŒ»ç–—é—®ç­”æœºå™¨äºº"ï¼Œä¸“ç²¾å„¿ç«¥å¥åº·å’¨è¯¢ã€‚

## äºŒã€å½“å‰å°è¯•è¿‡çš„ç¡¬ä»¶é…ç½®

æ˜¾å¡ï¼šNVIDIA GeForce RTX 4060

CPUï¼šIntel Core i7-13700H

å†…å­˜ï¼š16 G(å› ä¸ºå®¶åº­ç”µè„‘æ‰€ä»¥æ—¥å¸¸çŠ¶æ€æ˜¯ 8.8/15.7 GB)

## ä¸‰ã€å¾®è°ƒå·¥ä½œ

### (1) æ•°æ®é›†å‡†å¤‡

æœ¬æ–‡æ•°æ®é›†æ¥æºï¼Œé­”æ­ç¤¾åŒºçš„ medical-o1-reasoning-SFTã€‚

æœ¬æ–‡ä¸»è¦è¯´æ˜ï¼Œæ•°æ®é›†æ ¼å¼æ˜¯ï¼š
![img_2.png](../attachments/1/img_2.png)

åœ¨ DeepSeek çš„è’¸é¦æ¨¡å‹å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œæ•°æ®é›†ä¸­å¼•å…¥ Complex_CoTï¼ˆå¤æ‚æ€ç»´é“¾ï¼‰æ˜¯å…³é”®è®¾è®¡å·®å¼‚ã€‚è‹¥ä»…ä½¿ç”¨åŸºç¡€é—®ç­”å¯¹è¿›è¡Œè®­ç»ƒï¼Œæ¨¡å‹å°†éš¾ä»¥å……åˆ†ä¹ å¾—æ·±åº¦æ¨ç†èƒ½åŠ›ï¼Œå¯¼è‡´æœ€ç»ˆæ€§èƒ½æ˜¾è‘—ä½äºé¢„æœŸæ°´å¹³ã€‚è¿™ä¸€ç‰¹æ€§ä¸å¸¸è§„å¤§æ¨¡å‹å¾®è°ƒçš„æ•°æ®è¦æ±‚å­˜åœ¨æœ¬è´¨åŒºåˆ«ã€‚

![img_3.png](../attachments/1/img_3.png)

### (2) æ¨¡å‹å¾®è°ƒä»£ç ï¼ˆæ­¤å¤„æ˜¯æ— æ¡†æ¶çº¯æ‰‹æ“ï¼‰â€”â€”ç›´æ¥ä¸Šäº†ï¼Œåé¢ä¼šæœ‰ç»†èŠ‚è®²è§£

```aiignore
éœ€è¦å¼•å…¥çš„åº“ï¼š
pip install torch transformers peft datasets matplotlib accelerate safetensors
```
```python
import torch
import matplotlib.pyplot as plt
from transformers import (
    AutoTokenizer,
    AutoModelForCausalLM,
    TrainingArguments,
    Trainer,
    TrainerCallback
)
from peft import LoraConfig, get_peft_model
from datasets import load_dataset
import os

# é…ç½®è·¯å¾„ï¼ˆæ ¹æ®å®é™…è·¯å¾„ä¿®æ”¹ï¼‰
model_path = r"ä½ çš„æ¨¡å‹è·¯å¾„"  # æ¨¡å‹è·¯å¾„
data_path = r"ä½ çš„æ•°æ®é›†è·¯å¾„"  # æ•°æ®é›†è·¯å¾„
output_path = r"ä½ çš„ä¿å­˜å¾®è°ƒåçš„æ¨¡å‹è·¯å¾„"  # å¾®è°ƒåæ¨¡å‹ä¿å­˜è·¯å¾„

# å¼ºåˆ¶ä½¿ç”¨GPU
assert torch.cuda.is_available(), //"å¿…é¡»ä½¿ç”¨GPUè¿›è¡Œè®­ç»ƒï¼"
device = torch.device("cuda")

# è‡ªå®šä¹‰å›è°ƒè®°å½•Loss
class LossCallback(TrainerCallback):
    def __init__(self):
        self.losses = []

    def on_log(self, args, state, control, logs=None, **kwargs):
        if "loss" in logs:
            self.losses.append(logs["loss"])

# æ•°æ®é¢„å¤„ç†å‡½æ•°
def process_data(tokenizer):
    dataset = load_dataset("json", data_files=data_path, split="train[:1500]")

    def format_example(example):
        instruction = f"è¯Šæ–­é—®é¢˜ï¼š{example['Question']}\nè¯¦ç»†åˆ†æï¼š{example['Complex_CoT']}"
        inputs = tokenizer(
            f"{instruction}\n### ç­”æ¡ˆï¼š\n{example['Response']}<|endoftext|>",
            padding="max_length",
            truncation=True,
            max_length=512,
            return_tensors="pt"
        )
        return {"input_ids": inputs["input_ids"].squeeze(0), "attention_mask": inputs["attention_mask"].squeeze(0)}

    return dataset.map(format_example, remove_columns=dataset.column_names)

# LoRAé…ç½®
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    target_modules=["q_proj", "v_proj"],
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM"
)

# è®­ç»ƒå‚æ•°é…ç½®
training_args = TrainingArguments(
    output_dir=output_path,
    per_device_train_batch_size=2,  # æ˜¾å­˜ä¼˜åŒ–è®¾ç½®
    gradient_accumulation_steps=4,  # ç´¯è®¡æ¢¯åº¦ç›¸å½“äºbatch_size=8
    num_train_epochs=3,
    learning_rate=3e-4,
    fp16=True,  # å¼€å¯æ··åˆç²¾åº¦
    logging_steps=20,
    save_strategy="no",
    report_to="none",
    optim="adamw_torch",
    no_cuda=False,  # å¼ºåˆ¶ä½¿ç”¨CUDA
    dataloader_pin_memory=False,  # åŠ é€Ÿæ•°æ®åŠ è½½
    remove_unused_columns=False  # é˜²æ­¢åˆ é™¤æœªä½¿ç”¨çš„åˆ—
)

def main():
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_path, exist_ok=True)

    # åŠ è½½tokenizer
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    tokenizer.pad_token = tokenizer.eos_token

    # åŠ è½½æ¨¡å‹åˆ°GPU
    model = AutoModelForCausalLM.from_pretrained(
        model_path,
        torch_dtype=torch.float16,
        device_map={"": device}  # å¼ºåˆ¶ä½¿ç”¨æŒ‡å®šGPU
    )
    model = get_peft_model(model, peft_config)
    model.print_trainable_parameters()

    # å‡†å¤‡æ•°æ®
    dataset = process_data(tokenizer)

    # è®­ç»ƒå›è°ƒ
    loss_callback = LossCallback()

    # æ•°æ®åŠ è½½å™¨
    def data_collator(data):
        batch = {
            "input_ids": torch.stack([torch.tensor(d["input_ids"]) for d in data]).to(device),
            "attention_mask": torch.stack([torch.tensor(d["attention_mask"]) for d in data]).to(device),
            "labels": torch.stack([torch.tensor(d["input_ids"]) for d in data]).to(device)  # ä½¿ç”¨input_idsä½œä¸ºlabels
        }
        return batch

    # åˆ›å»ºTrainer
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=dataset,
        data_collator=data_collator,
        callbacks=[loss_callback]
    )

    # å¼€å§‹è®­ç»ƒ
    print("å¼€å§‹è®­ç»ƒ...")
    trainer.train()

    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    trainer.model.save_pretrained(output_path)
    print(f"æ¨¡å‹å·²ä¿å­˜è‡³ï¼š{output_path}")

    # ç»˜åˆ¶è®­ç»ƒé›†æŸå¤±Lossæ›²çº¿
    plt.figure(figsize=(10, 6))
    plt.plot(loss_callback.losses)
    plt.title("Training Loss Curve")
    plt.xlabel("Steps")
    plt.ylabel("Loss")
    plt.savefig(os.path.join(output_path, "loss_curve.png"))
    print("Lossæ›²çº¿å·²ä¿å­˜")

if __name__ == "__main__":
    main()
```

### (3) ä»£ç è¯¦ç»†è®²è§£
 - a. å¯¼å…¥å¿…è¦çš„åº“å’Œæ¨¡å—

 åŠŸèƒ½æ€»ç»“ï¼šå¯¼å…¥é¡¹ç›®ä¾èµ–çš„ç¬¬ä¸‰æ–¹åº“ï¼ŒåŒ…æ‹¬ PyTorch åŸºç¡€åº“ã€HuggingFace å·¥å…·åº“ã€å¯è§†åŒ–åº“ç­‰ã€‚
 ```python
import torch
import matplotlib.pyplot as plt
from transformers import (  # HuggingFace Transformeræ¨¡å‹å·¥å…·
    AutoTokenizer,
    AutoModelForCausalLM,
    TrainingArguments,
    Trainer,
    TrainerCallback
)
from peft import LoraConfig, get_peft_model  # å‚æ•°é«˜æ•ˆå¾®è°ƒåº“
from datasets import load_dataset  # æ•°æ®é›†åŠ è½½å·¥å…·
import os  # ç³»ç»Ÿè·¯å¾„æ“ä½œ
```

## æœ‰å…³ç±»åº“ä»‹ç»ï¼š

1.  **torch (PyTorch åº“çš„æ ¸å¿ƒæ¨¡å—)**

  * åŠŸèƒ½ï¼šæ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæä¾›å¼ é‡è®¡ç®—å’Œç¥ç»ç½‘ç»œæ„å»ºåŠŸèƒ½ã€‚
  * ä»£ç ä¸­çš„ä½œç”¨ï¼š
    * ç®¡ç† GPU è®¾å¤‡ (torch.cuda.is_available() æ£€æŸ¥ GPU å¯ç”¨æ€§)
    * å®šä¹‰æ¨¡å‹è®­ç»ƒæ—¶çš„å¼ é‡æ“ä½œ
    * æ§åˆ¶æ··åˆç²¾åº¦è®­ç»ƒ (torch.float16)

2.  **matplotlib.pyplot (Matplotlib ç»˜å›¾åº“)**

  * åŠŸèƒ½ï¼šæ•°æ®å¯è§†åŒ–å·¥å…·åº“ã€‚
  * ä»£ç ä¸­çš„ä½œç”¨ï¼š
    * ç»˜åˆ¶è®­ç»ƒæŸå¤±æ›²çº¿ (plt.plot(losses))
    * ç”Ÿæˆå¹¶ä¿å­˜è®­ç»ƒè¿‡ç¨‹çš„ Loss å˜åŒ–å›¾ (loss_curve.png)

3.  **transformers (HuggingFace Transformers åº“)**

  * æ ¸å¿ƒç»„ä»¶ï¼š
    * AutoTokenizerï¼šè‡ªåŠ¨åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å¯¹åº”çš„åˆ†è¯å™¨
      * ç”¨äºå°†æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹å¯ç†è§£çš„ token ID åºåˆ—
    * AutoModelForCausalLMï¼šè‡ªåŠ¨åŠ è½½å› æœè¯­è¨€æ¨¡å‹ï¼ˆå¦‚ GPT ç³»åˆ—ï¼‰
      * æä¾›åŸºç¡€çš„å¤§è¯­è¨€æ¨¡å‹ç»“æ„
    * TrainingArgumentsï¼šå®šä¹‰è®­ç»ƒè¶…å‚æ•°
      * æ§åˆ¶æ‰¹æ¬¡å¤§å°ã€å­¦ä¹ ç‡ã€æ—¥å¿—é¢‘ç‡ç­‰
    * Trainerï¼šå°è£…è®­ç»ƒæµç¨‹çš„ç±»
      * è‡ªåŠ¨å¤„ç†è®­ç»ƒå¾ªç¯ã€æ¢¯åº¦ä¸‹é™ã€æ—¥å¿—è®°å½•ç­‰
    * TrainerCallbackï¼šè®­ç»ƒå›è°ƒåŸºç±»
      * ç”¨äºå®ç°è‡ªå®šä¹‰è®­ç»ƒç›‘æ§é€»è¾‘ï¼ˆå¦‚ç¤ºä¾‹ä¸­çš„æŸå¤±è®°å½•ï¼‰

4.  **peft (Parameter-Efficient Fine-Tuning)**

  * åŠŸèƒ½ï¼šå®ç°å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•çš„åº“ã€‚
  * æ ¸å¿ƒç»„ä»¶ï¼š
    * LoraConfigï¼šLoRAï¼ˆLow-Rank Adaptationï¼‰çš„é…ç½®ç±»
      * å®šä¹‰ç§©(r)ã€ç›®æ ‡æ¨¡å—(target_modules)ç­‰å…³é”®å‚æ•°
    * get_peft_modelï¼šå°†åŸºç¡€æ¨¡å‹è½¬æ¢ä¸º PEFT æ¨¡å‹
      * ä»…éœ€è®­ç»ƒåŸæ¨¡å‹çº¦ 0.1% çš„å‚æ•°å³å¯å®ç°æœ‰æ•ˆå¾®è°ƒ
  * ä»£ç ä¸­çš„ä½œç”¨ï¼š
    * å¯¹ LLaMA ç­‰å¤§æ¨¡å‹è¿›è¡Œè½»é‡åŒ–å¾®è°ƒ
    * æ˜¾å­˜å ç”¨é‡å‡å°‘çº¦ 60-70%ï¼Œé€‚åˆæ¶ˆè´¹çº§ GPU

5.  **datasets (HuggingFace Datasets åº“)**

  * åŠŸèƒ½ï¼šé«˜æ•ˆæ•°æ®é›†åŠ è½½ä¸å¤„ç†å·¥å…·ã€‚
  * æ ¸å¿ƒæ–¹æ³•ï¼š
    * load_datasetï¼šåŠ è½½å¤šç§æ ¼å¼çš„æ•°æ®
      * æ”¯æŒ JSON/CSV/Parquet ç­‰æ ¼å¼ï¼ˆç¤ºä¾‹ä¸­ä½¿ç”¨ JSONï¼‰
    * mapï¼šæ•°æ®é¢„å¤„ç†æµæ°´çº¿
      * åº”ç”¨è‡ªå®šä¹‰çš„æ ¼å¼åŒ–å‡½æ•° (format_example)
  * ä»£ç ä¸­çš„ä½œç”¨ï¼š
    * ä»æœ¬åœ°æ–‡ä»¶åŠ è½½åŒ»ç–—é—®ç­”æ•°æ®é›†
    * å°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºæ¨¡å‹éœ€è¦çš„è¾“å…¥æ ¼å¼

6.  **os (æ“ä½œç³»ç»Ÿæ¥å£)**

  * åŠŸèƒ½ï¼šæä¾›æ“ä½œç³»ç»Ÿç›¸å…³åŠŸèƒ½ã€‚
  * ä»£ç ä¸­çš„ä½œç”¨ï¼š
    * åˆ›å»ºè¾“å‡ºç›®å½• (os.makedirs)
    * å¤„ç†æ–‡ä»¶è·¯å¾„ç›¸å…³æ“ä½œ
    * ç¡®ä¿æ¨¡å‹ä¿å­˜è·¯å¾„çš„æœ‰æ•ˆæ€§

## 2. é…ç½®è·¯å¾„å’Œç¡¬ä»¶æ£€æŸ¥

* åŠŸèƒ½æ€»ç»“ï¼šé…ç½®æ¨¡å‹/æ•°æ®è·¯å¾„ï¼Œå¼ºåˆ¶æ£€æŸ¥ GPU å¯ç”¨æ€§

```python
# é…ç½®è·¯å¾„ï¼ˆæ ¹æ®å®é™…è·¯å¾„ä¿®æ”¹ï¼‰
model_path = r"ä½ çš„æ¨¡å‹è·¯å¾„"  # é¢„è®­ç»ƒæ¨¡å‹å­˜æ”¾è·¯å¾„
data_path = r"ä½ çš„æ•°æ®é›†è·¯å¾„"  # è®­ç»ƒæ•°æ®è·¯å¾„ï¼ˆJSONæ ¼å¼ï¼‰
output_path = r"ä½ çš„ä¿å­˜å¾®è°ƒåçš„æ¨¡å‹è·¯å¾„"  # å¾®è°ƒåæ¨¡å‹ä¿å­˜ä½ç½®

# å¼ºåˆ¶ä½¿ç”¨GPUï¼ˆç¡®ä¿CUDAå¯ç”¨ï¼‰
assert torch.cuda.is_available(), "å¿…é¡»ä½¿ç”¨GPUè¿›è¡Œè®­ç»ƒï¼"
device = torch.device("cuda")  # æŒ‡å®šä½¿ç”¨CUDAè®¾å¤‡
```

3. è‡ªå®šä¹‰è®­ç»ƒå›è°ƒç±»
* åŠŸèƒ½æ€»ç»“ï¼šå®ç°è‡ªå®šä¹‰å›è°ƒï¼Œåœ¨æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå®æ—¶è®°å½•æŸå¤±å€¼ï¼ˆLossï¼‰çš„å˜åŒ–ã€‚æŸå¤±å€¼æ˜¯ç”¨æ¥è¡¡é‡æ¨¡å‹é¢„æµ‹ç»“æœä¸çœŸå®ç»“æœä¹‹é—´çš„å·®è·çš„ï¼ŒæŸå¤±å€¼è¶Šå°ï¼Œè¯´æ˜æ¨¡å‹çš„è¡¨ç°è¶Šå¥½ã€‚

```python
class LossCallback(TrainerCallback):
    def __init__(self):
        self.losses = []  # å­˜å‚¨æŸå¤±å€¼çš„åˆ—è¡¨

    # å½“è®­ç»ƒè¿‡ç¨‹ä¸­æœ‰æ—¥å¿—è¾“å‡ºæ—¶è§¦å‘
    def on_log(self, args, state, control, logs=None, **kwargs):
        if "loss" in logs:  # è¿‡æ»¤å¹¶è®°å½•æŸå¤±å€¼
            self.losses.append(logs["loss"])
```

4. æ•°æ®é¢„å¤„ç†å‡½æ•°
* åŠŸèƒ½æ€»ç»“ï¼šåŠ è½½å¹¶æ ¼å¼åŒ–è®­ç»ƒæ•°æ®ï¼Œå°†åŸå§‹æ•°æ®é›†è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥ç†è§£çš„æ ¼å¼ã€‚

```python
def process_data(tokenizer):
    # ä»JSONæ–‡ä»¶åŠ è½½æ•°æ®é›†ï¼ˆä»…å–å‰1500æ¡ï¼‰
    dataset = load_dataset("json", data_files=data_path, split="train[:1500]")

    # å•æ¡æ•°æ®æ ¼å¼åŒ–å‡½æ•°
    def format_example(example):
        # æ‹¼æ¥æŒ‡ä»¤å’Œç­”æ¡ˆï¼ˆå›ºå®šæ¨¡æ¿ï¼‰
        instruction = f"è¯Šæ–­é—®é¢˜ï¼š{example['Question']}\nè¯¦ç»†åˆ†æï¼š{example['Complex_CoT']}"
        inputs = tokenizer(
            f"{instruction}\n### ç­”æ¡ˆï¼š\n{example['Response']}<|endoftext|>",  # æ·»åŠ ç»“æŸç¬¦
            padding="max_length",  # å¡«å……è‡³æœ€å¤§é•¿åº¦
            truncation=True,       # è¶…é•¿æˆªæ–­
            max_length=512,        # æœ€å¤§åºåˆ—é•¿åº¦
            return_tensors="pt"    # è¿”å›PyTorchå¼ é‡
        )
        # è¿”å›å¤„ç†åçš„è¾“å…¥ï¼ˆç§»é™¤batchç»´åº¦ï¼‰
        return {"input_ids": inputs["input_ids"].squeeze(0), 
                "attention_mask": inputs["attention_mask"].squeeze(0)}

    # åº”ç”¨æ ¼å¼åŒ–å‡½æ•°å¹¶ç§»é™¤åŸå§‹åˆ—
    return dataset.map(format_example, remove_columns=dataset.column_names)
```

#### å…³é”®ä»£ç 

1.æ‹¼æ¥æŒ‡ä»¤å’Œç­”æ¡ˆ

- ä½œç”¨ï¼šå°†é—®é¢˜ï¼ˆQuestionï¼‰å’Œè¯¦ç»†åˆ†æï¼ˆComplex_CoTï¼‰æ‹¼æ¥æˆä¸€ä¸ªæŒ‡ä»¤ã€‚

- ç¤ºä¾‹ï¼š

  - è¾“å…¥ï¼šQuestion="å‘çƒ§æ€ä¹ˆåŠï¼Ÿ", Complex_CoT="å¯èƒ½æ˜¯æ„Ÿå†’å¼•èµ·çš„ã€‚"
  - è¾“å‡ºï¼š"è¯Šæ–­é—®é¢˜ï¼šå‘çƒ§æ€ä¹ˆåŠï¼Ÿ\nè¯¦ç»†åˆ†æï¼šå¯èƒ½æ˜¯æ„Ÿå†’å¼•èµ·çš„ã€‚"
- ç±»æ¯”ï¼šå°±åƒæŠŠé—®é¢˜å’Œåˆ†æå†™åœ¨ä¸€å¼ çº¸ä¸Šã€‚

```python
instruction = f"è¯Šæ–­é—®é¢˜ï¼š{example['Question']}\nè¯¦ç»†åˆ†æï¼š{example['Complex_CoT']}"
```

#### ä½¿ç”¨åˆ†è¯å™¨å¤„ç†æ–‡æœ¬

- ä½œç”¨ï¼šå°†æ‹¼æ¥åçš„æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥ç†è§£çš„æ ¼å¼ã€‚
- å‚æ•°è¯´æ˜ï¼š
  - padding="max_length"ï¼šå°†æ–‡æœ¬å¡«å……åˆ°å›ºå®šé•¿åº¦ï¼ˆ512ï¼‰ã€‚
  - truncation=Trueï¼šå¦‚æœæ–‡æœ¬è¶…è¿‡ 512 ä¸ª tokenï¼Œå°±æˆªæ–­ã€‚
  - max_length=512ï¼šæœ€å¤§é•¿åº¦ä¸º 512ã€‚
  - return_tensors="pt"ï¼šè¿”å› PyTorch å¼ é‡ã€‚
- ç¤ºä¾‹ï¼š
  - è¾“å…¥ï¼š"è¯Šæ–­é—®é¢˜ï¼šå‘çƒ§æ€ä¹ˆåŠï¼Ÿ\nè¯¦ç»†åˆ†æï¼šå¯èƒ½æ˜¯æ„Ÿå†’å¼•èµ·çš„ã€‚\n### ç­”æ¡ˆï¼š\nå¤šå–æ°´ï¼Œä¼‘æ¯ã€‚"
  - è¾“å‡ºï¼šinput_ids=[101, 234, 345, ..., 102], attention_mask=[1, 1, 1, ..., 1]
- ç±»æ¯”ï¼šå°±åƒæŠŠæ–‡å­—ç¿»è¯‘æˆæœºå™¨èƒ½æ‡‚çš„æ•°å­—ã€‚

```python
inputs = tokenizer(
    f"{instruction}\n### ç­”æ¡ˆï¼š\n{example['Response']}<|endoftext|>",  # æ·»åŠ ç»“æŸç¬¦
    padding="max_length",  # å¡«å……è‡³æœ€å¤§é•¿åº¦
    truncation=True,       # è¶…é•¿æˆªæ–­
    max_length=512,        # æœ€å¤§åºåˆ—é•¿åº¦
    return_tensors="pt"    # è¿”å›PyTorchå¼ é‡
)
```

3. è¿”å›å¤„ç†åçš„è¾“å…¥

- ä½œç”¨ï¼šè¿”å›å¤„ç†åçš„è¾“å…¥æ•°æ®ï¼Œå¹¶ç§»é™¤å¤šä½™çš„ç»´åº¦ã€‚
- å‚æ•°è¯´æ˜ï¼š
  - input_idsï¼šæ–‡æœ¬å¯¹åº”çš„ token ID åºåˆ—ã€‚
  - attention_maskï¼šæ ‡è®°å“ªäº›ä½ç½®æ˜¯æœ‰æ•ˆ tokenï¼ˆ1 è¡¨ç¤ºæœ‰æ•ˆï¼Œ0 è¡¨ç¤ºå¡«å……ï¼‰ã€‚
- ç±»æ¯”ï¼šå°±åƒæŠŠç¿»è¯‘å¥½çš„æ•°å­—æ•´ç†æˆä¸€å¼ è¡¨æ ¼ã€‚
```python
return {"input_ids": inputs["input_ids"].squeeze(0), 
        "attention_mask": inputs["attention_mask"].squeeze(0)}
```

4. åº”ç”¨æ ¼å¼åŒ–å‡½æ•°

- ä½œç”¨ï¼šå¯¹æ•´ä¸ªæ•°æ®é›†åº”ç”¨æ ¼å¼åŒ–å‡½æ•°ï¼Œå¹¶ç§»é™¤åŸå§‹åˆ—ã€‚
- å‚æ•°è¯´æ˜ï¼š
  - format_exampleï¼šæ ¼å¼åŒ–å‡½æ•°ã€‚
  - remove_columns=dataset.column_namesï¼šç§»é™¤åŸå§‹åˆ—ï¼ˆå¦‚ Questionã€Complex_CoT ç­‰ï¼‰ã€‚
- ç±»æ¯”ï¼šå°±åƒæŠŠæ•´æœ¬ä¹¦çš„æ¯ä¸€é¡µéƒ½ç¿»è¯‘æˆæœºå™¨èƒ½æ‡‚çš„æ ¼å¼ã€‚
```python 
return dataset.map(format_example, remove_columns=dataset.column_names)
```
5. LoRAå¾®è°ƒé…ç½®

   åŠŸèƒ½æ€»ç»“ï¼šé…ç½®LoRAå‚æ•°ï¼ŒæŒ‡å®šè¦é€‚é…çš„æ¨¡å‹æ¨¡å—ã€‚

```python
peft_config = LoraConfig(
    r=16,               # LoRAç§©ï¼ˆçŸ©é˜µåˆ†è§£ç»´åº¦ï¼‰
    lora_alpha=32,      # ç¼©æ”¾ç³»æ•°ï¼ˆæ§åˆ¶é€‚é…å™¨å½±å“å¼ºåº¦ï¼‰
    target_modules=["q_proj", "v_proj"],  # è¦é€‚é…çš„æ³¨æ„åŠ›æ¨¡å—ï¼ˆæŸ¥è¯¢/å€¼æŠ•å½±ï¼‰
    lora_dropout=0.05,  # é˜²æ­¢è¿‡æ‹Ÿåˆçš„Dropoutç‡
    bias="none",        # ä¸è®­ç»ƒåç½®å‚æ•°
    task_type="CAUSAL_LM"  # ä»»åŠ¡ç±»å‹ï¼ˆå› æœè¯­è¨€æ¨¡å‹ï¼‰
)
```

1. r=16ï¼šLoRA çš„ç§©
- ä½œç”¨ï¼šæ§åˆ¶ä½ç§©çŸ©é˜µçš„ç»´åº¦ã€‚ç§©è¶Šå°ï¼Œå‚æ•°è¶Šå°‘ï¼Œè®¡ç®—é‡è¶Šå°ã€‚
- è§£é‡Šï¼š
  - ç§©ï¼ˆrï¼‰æ˜¯ä½ç§©çŸ©é˜µçš„åˆ†è§£ç»´åº¦ï¼Œå†³å®šäº†ä½ç§©çŸ©é˜µçš„å¤§å°ã€‚
  - ä¾‹å¦‚ï¼Œr=16 è¡¨ç¤ºä½ç§©çŸ©é˜µçš„ç»´åº¦æ˜¯ 16ã€‚
- å½±å“ï¼š
  - è¾ƒå°çš„ r ä¼šå‡å°‘å‚æ•°é‡ï¼Œä½†å¯èƒ½ä¼šé™ä½æ¨¡å‹çš„è¡¨ç°ã€‚
  - è¾ƒå¤§çš„ r ä¼šå¢åŠ å‚æ•°é‡ï¼Œä½†å¯èƒ½ä¼šæé«˜æ¨¡å‹çš„è¡¨ç°ã€‚

- æ¯”å–»ï¼š
  - "ç›¸å½“äºç»™AIçš„â€˜å­¦ä¹ ç¬”è®°â€™è®¾ç½® 16 é¡µçš„ç¯‡å¹…é™åˆ¶"

â†’ é¡µæ•°å°‘ï¼ˆrå°ï¼‰ï¼šå­¦å¾—å¿«ä½†å¯èƒ½æ¼ç»†èŠ‚

â†’ é¡µæ•°å¤šï¼ˆrå¤§ï¼‰ï¼šå­¦å¾—ç»†ä½†é€Ÿåº¦æ…¢
  - é»˜è®¤å€¼ï¼šé€šå¸¸è®¾ç½®ä¸º 8 æˆ– 16ã€‚å¹¶éè¶Šå¤§è¶Šå¥½ã€‚LoRA ç§©çš„é€‰æ‹©éœ€è¦å¹³è¡¡æ¨¡å‹çš„é€‚åº”èƒ½åŠ›å’Œè®¡ç®—æ•ˆç‡ã€‚è¾ƒå¤§çš„ç§©å¯ä»¥æä¾›æ›´å¼ºçš„è¡¨è¾¾èƒ½åŠ›ï¼Œä½†ä¼šå¢åŠ è®¡ç®—é‡å’Œæ˜¾å­˜å ç”¨ï¼ŒåŒæ—¶å¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆã€‚å¯¹äºç®€å•ä»»åŠ¡ï¼Œé€šå¸¸æ¨èä½¿ç”¨è¾ƒå°çš„ç§©ï¼ˆå¦‚ 4 æˆ– 8ï¼‰ï¼Œè€Œå¯¹äºå¤æ‚ä»»åŠ¡ï¼Œå¯èƒ½éœ€è¦æ›´é«˜çš„ç§©ï¼ˆå¦‚ 16 æˆ– 32ï¼‰

2. lora_alpha=32ï¼šç¼©æ”¾ç³»æ•°
- ä½œç”¨ï¼šæ§åˆ¶ä½ç§©çŸ©é˜µå¯¹åŸå§‹æ¨¡å‹çš„å½±å“å¼ºåº¦ã€‚
- è§£é‡Šï¼š
  - lora_alpha æ˜¯ä¸€ä¸ªç¼©æ”¾å› å­ï¼Œç”¨äºè°ƒæ•´ä½ç§©çŸ©é˜µçš„è¾“å‡ºã€‚
  - å…·ä½“æ¥è¯´ï¼Œä½ç§©çŸ©é˜µçš„è¾“å‡ºä¼šä¹˜ä»¥ lora_alpha / rã€‚
- å½±å“ï¼š
  - è¾ƒå¤§çš„ lora_alpha ä¼šè®©ä½ç§©çŸ©é˜µçš„å½±å“æ›´å¼ºã€‚
  - è¾ƒå°çš„ lora_alpha ä¼šè®©ä½ç§©çŸ©é˜µçš„å½±å“æ›´å¼±ã€‚
- æ¯”å–»ï¼š
  å°±åƒæ˜¯ï¼ŒéŸ³é‡æ—‹é’®çš„å¤§å°å†³å®šäº†å£°éŸ³çš„å“äº®ç¨‹åº¦ã€‚å¦‚æœæ—‹é’®è½¬å¾—å¤ªå¤§ï¼Œå£°éŸ³å¯èƒ½ä¼šéœ‡è€³æ¬²è‹ï¼Œç”šè‡³è®©äººéš¾ä»¥å¿å—ï¼›å¦‚æœæ—‹é’®è½¬å¾—å¤ªå°ï¼Œå£°éŸ³åˆå¯èƒ½å¤ªå°ï¼Œå¬ä¸æ¸…æ¥šã€‚
  
  è¿‡å¤§çš„ lora_alpha å¯èƒ½ä¼šå¯¼è‡´æ¨¡å‹çš„è®­ç»ƒå˜å¾—ä¸ç¨³å®šï¼Œå°±åƒå£°éŸ³å¤ªå¤§å¯èƒ½ä¼šè®©äººæ„Ÿåˆ°ä¸é€‚ä¸€æ ·ã€‚å¯èƒ½ä¼šå¯¼è‡´è¿‡æ‹Ÿåˆï¼Œå› ä¸ºæ¨¡å‹å¯¹è®­ç»ƒæ•°æ®çš„ç»†èŠ‚è°ƒæ•´è¿‡äºæ•æ„Ÿã€‚
  
  è¾ƒå°çš„ lora_alpha ä¼šå¯¼è‡´æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šæ›´ä¿å®ˆåœ°è°ƒæ•´æƒé‡ï¼Œè®­ç»ƒè¿‡ç¨‹æ›´ç¨³å®šï¼Œä½†é€‚åº”æ–°ä»»åŠ¡çš„é€Ÿåº¦å¯èƒ½ä¼šè¾ƒæ…¢ã€‚

  - é»˜è®¤å€¼ï¼šé€šå¸¸è®¾ç½®ä¸º 32ã€‚

3. target_modules=["q_proj", "v_proj"]ï¼šç›®æ ‡æ¨¡å—
   - ä½œç”¨ï¼šæŒ‡å®šéœ€è¦æ’å…¥ä½ç§©çŸ©é˜µçš„æ¨¡å‹æ¨¡å—ã€‚
   - è§£é‡Šï¼š
     - q_proj å’Œ v_proj æ˜¯ Transformer æ¨¡å‹ä¸­çš„æ³¨æ„åŠ›æœºåˆ¶æ¨¡å—ï¼š
     - q_projï¼šæŸ¥è¯¢ï¼ˆQueryï¼‰æŠ•å½±çŸ©é˜µã€‚
     - v_projï¼šå€¼ï¼ˆValueï¼‰æŠ•å½±çŸ©é˜µã€‚
     - LoRA ä¼šåœ¨è¿™ä¸¤ä¸ªæ¨¡å—ä¸­æ’å…¥ä½ç§©çŸ©é˜µã€‚
   - å½±å“ï¼š
     - é€‰æ‹©ä¸åŒçš„æ¨¡å—ä¼šå½±å“å¾®è°ƒçš„æ•ˆæœã€‚
     - é€šå¸¸é€‰æ‹© q_proj å’Œ v_proj æ˜¯å› ä¸ºå®ƒä»¬å¯¹æ¨¡å‹çš„è¡¨ç°å½±å“è¾ƒå¤§

4. lora_dropout=0.05ï¼šDropout ç‡
   - ä½œç”¨ï¼šé˜²æ­¢è¿‡æ‹Ÿåˆã€‚
   - è§£é‡Šï¼š
     - Dropout æ˜¯ä¸€ç§æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œéšæœºä¸¢å¼ƒä¸€éƒ¨åˆ†ç¥ç»å…ƒï¼Œé˜²æ­¢æ¨¡å‹è¿‡åº¦ä¾èµ–æŸäº›ç‰¹å¾ã€‚
     - lora_dropout=0.05 è¡¨ç¤ºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæœ‰ 5% çš„ä½ç§©çŸ©é˜µå‚æ•°ä¼šè¢«éšæœºä¸¢å¼ƒã€‚
   - å½±å“ï¼š
     - è¾ƒå¤§çš„ Dropout ç‡ä¼šå¢åŠ æ¨¡å‹çš„é²æ£’æ€§ï¼Œä½†å¯èƒ½ä¼šé™ä½è®­ç»ƒæ•ˆç‡ã€‚
     - è¾ƒå°çš„ Dropout ç‡ä¼šå‡å°‘æ­£åˆ™åŒ–æ•ˆæœï¼Œä½†å¯èƒ½ä¼šæé«˜è®­ç»ƒé€Ÿåº¦ã€‚

5. bias="none"ï¼šåç½®å‚æ•°
- ä½œç”¨ï¼šæ§åˆ¶æ˜¯å¦è®­ç»ƒåç½®å‚æ•°ã€‚åç½®å‚æ•°çš„ä½œç”¨æ˜¯ä¸ºæ¨¡å‹çš„è¾“å‡ºæä¾›ä¸€ä¸ªåŸºçº¿åç§»ï¼ˆbaseline offsetï¼‰ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°æ‹Ÿåˆæ•°æ®ã€‚
- è§£é‡Šï¼š
  - bias="none" è¡¨ç¤ºä¸è®­ç»ƒåç½®å‚æ•°ã€‚
  - å…¶ä»–é€‰é¡¹åŒ…æ‹¬ "all"ï¼ˆè®­ç»ƒæ‰€æœ‰åç½®å‚æ•°ï¼‰å’Œ "lora_only"ï¼ˆåªè®­ç»ƒ LoRA ç›¸å…³çš„åç½®å‚æ•°ï¼‰ã€‚
- å½±å“ï¼š
  - ä¸è®­ç»ƒåç½®å‚æ•°å¯ä»¥å‡å°‘å‚æ•°é‡ï¼Œä½†å¯èƒ½ä¼šå½±å“æ¨¡å‹çš„è¡¨ç°ã€‚

6. task_type="CAUSAL_LM"ï¼šä»»åŠ¡ç±»å‹
- ä½œç”¨ï¼šæŒ‡å®šä»»åŠ¡ç±»å‹ã€‚
-è§£é‡Šï¼š
  - CAUSAL_LM è¡¨ç¤ºå› æœè¯­è¨€æ¨¡å‹ï¼ˆCausal Language Modelï¼‰ï¼Œå³ç”Ÿæˆå¼ä»»åŠ¡ï¼ˆå¦‚ GPTï¼‰ã€‚
  - å…¶ä»–ä»»åŠ¡ç±»å‹åŒ…æ‹¬åºåˆ—åˆ†ç±»ï¼ˆSEQ_CLSï¼‰ã€åºåˆ—åˆ°åºåˆ—ï¼ˆSEQ_2_SEQï¼‰ç­‰ã€‚
- å½±å“ï¼š
  - ä¸åŒçš„ä»»åŠ¡ç±»å‹ä¼šå½±å“ LoRA çš„å®ç°æ–¹å¼ã€‚

### è®­ç»ƒå‚æ•°é…ç½®
```python 
training_args = TrainingArguments(
    output_dir=output_path,        # è¾“å‡ºç›®å½•ï¼ˆæ¨¡å‹/æ—¥å¿—ï¼‰
    per_device_train_batch_size=2, # å•GPUæ‰¹æ¬¡å¤§å°ï¼ˆæ˜¾å­˜ä¼˜åŒ–ï¼‰
    gradient_accumulation_steps=4, # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼ˆç­‰æ•ˆbatch_size=8ï¼‰
    num_train_epochs=3,            # è®­ç»ƒè½®æ¬¡
    learning_rate=3e-4,            # åˆå§‹å­¦ä¹ ç‡
    fp16=True,                     # å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆèŠ‚çœæ˜¾å­˜ï¼‰
    logging_steps=20,              # æ¯éš”20æ­¥è®°å½•æ—¥å¿—
    save_strategy="no",            # ä¸ä¿å­˜ä¸­é—´æ£€æŸ¥ç‚¹
    report_to="none",              # ç¦ç”¨ç¬¬ä¸‰æ–¹æŠ¥å‘Šï¼ˆå¦‚W&Bï¼‰
    optim="adamw_torch",           # ä¼˜åŒ–å™¨ç±»å‹
    no_cuda=False,                 # å¼ºåˆ¶ä½¿ç”¨CUDA
    dataloader_pin_memory=False,   # ç¦ç”¨é”é¡µå†…å­˜ï¼ˆåŠ é€Ÿæ•°æ®åŠ è½½ï¼‰
    remove_unused_columns=False    # ä¿ç•™æœªä½¿ç”¨çš„åˆ—ï¼ˆé¿å…æ•°æ®é”™è¯¯ï¼‰
)
```

1. output_dir=output_pathï¼šè¾“å‡ºç›®å½•
   - ä½œç”¨ï¼šæŒ‡å®šè®­ç»ƒè¿‡ç¨‹ä¸­æ¨¡å‹å’Œæ—¥å¿—çš„ä¿å­˜è·¯å¾„ã€‚æ­¤å¤„çš„ output_path ä¹‹å‰å·²ç»å†™åœ¨äº†æœ€å‰é¢çš„å˜é‡ä¹‹ä¸­ã€‚
   - è§£é‡Šï¼š
     - è®­ç»ƒè¿‡ç¨‹ä¸­ç”Ÿæˆçš„æ¨¡å‹æ£€æŸ¥ç‚¹ã€æ—¥å¿—æ–‡ä»¶ç­‰éƒ½ä¼šä¿å­˜åˆ°è¿™ä¸ªç›®å½•ã€‚
   - ç¤ºä¾‹ï¼š
     - å¦‚æœ output_path = "./output"ï¼Œæ‰€æœ‰æ–‡ä»¶éƒ½ä¼šä¿å­˜åˆ° ./output ç›®å½•ä¸‹ã€‚

## è®­ç»ƒå‚æ•°é…ç½®

* åŠŸèƒ½æ€»ç»“ï¼šè®¾ç½®è®­ç»ƒè¶…å‚æ•°å’Œç¡¬ä»¶ç›¸å…³é€‰é¡¹ã€‚

1.  **per_device_train_batch_size=2ï¼šå• GPU æ‰¹æ¬¡å¤§å°**

  * ä½œç”¨ï¼šè®¾ç½®æ¯ä¸ª GPU ä¸Šçš„è®­ç»ƒæ‰¹æ¬¡å¤§å°ã€‚
  * è§£é‡Šï¼š
    * æ‰¹æ¬¡å¤§å°æ˜¯æŒ‡æ¯æ¬¡è¾“å…¥æ¨¡å‹çš„æ ·æœ¬æ•°é‡ã€‚
    * è¾ƒå°çš„æ‰¹æ¬¡å¤§å°å¯ä»¥èŠ‚çœæ˜¾å­˜ï¼Œä½†å¯èƒ½ä¼šé™ä½è®­ç»ƒé€Ÿåº¦ã€‚
  * ç¤ºä¾‹ï¼š
    * å¦‚æœä½¿ç”¨ 1 ä¸ª GPUï¼Œæ¯æ¬¡è®­ç»ƒä¼šè¾“å…¥ 2 æ¡æ•°æ®ã€‚

2.  **gradient_accumulation_steps=4ï¼šæ¢¯åº¦ç´¯ç§¯æ­¥æ•°**

  * ä½œç”¨ï¼šè®¾ç½®æ¢¯åº¦ç´¯ç§¯çš„æ­¥æ•°ï¼Œç”¨äºæ¨¡æ‹Ÿæ›´å¤§çš„æ‰¹æ¬¡å¤§å°ã€‚
  * è§£é‡Šï¼š
    * æ¢¯åº¦ç´¯ç§¯æ˜¯æŒ‡åœ¨å¤šæ¬¡å°æ‰¹æ¬¡çš„å‰å‘ä¼ æ’­åï¼Œç´¯ç§¯æ¢¯åº¦ï¼Œç„¶ååœ¨ä¸€æ¬¡åå‘ä¼ æ’­ä¸­æ›´æ–°æƒé‡ã€‚
    * å®ƒå¯ä»¥æ¨¡æ‹Ÿæ›´å¤§çš„æ‰¹æ¬¡å¤§å°ï¼Œä»è€Œæé«˜æ¨¡å‹çš„è®­ç»ƒæ•ˆæœï¼ŒåŒæ—¶é¿å…æ˜¾å­˜ä¸è¶³çš„é—®é¢˜ã€‚
    * å®é™…æ‰¹æ¬¡å¤§å° = per_device_train_batch_size * gradient_accumulation_stepsã€‚
  * ç¤ºä¾‹ï¼š
    * å¦‚æœ per_device_train_batch_size=2ï¼Œgradient_accumulation_steps=4ï¼Œåˆ™å®é™…æ‰¹æ¬¡å¤§å°ä¸º 8ã€‚

3.  **num_train_epochs=3ï¼šè®­ç»ƒè½®æ¬¡**

  * ä½œç”¨ï¼šè®¾ç½®æ¨¡å‹åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šè®­ç»ƒçš„è½®æ¬¡ã€‚
  * è§£é‡Šï¼š
    * 1 ä¸ªè½®æ¬¡ï¼ˆepochï¼‰è¡¨ç¤ºæ¨¡å‹å®Œæ•´åœ°éå†ä¸€æ¬¡è®­ç»ƒæ•°æ®é›†ã€‚
    * è¿™é‡Œè®¾ç½®ä¸º 3ï¼Œè¡¨ç¤ºæ¨¡å‹ä¼šè®­ç»ƒ 3 è½®ã€‚
  * ç¤ºä¾‹ï¼š
    * å¦‚æœæ•°æ®é›†æœ‰ 1000 æ¡æ•°æ®ï¼Œæ¨¡å‹ä¼šéå†è¿™ 1000 æ¡æ•°æ® 3 æ¬¡ã€‚

4.  **learning_rate=3e-4ï¼šåˆå§‹å­¦ä¹ ç‡**

  * ä½œç”¨ï¼šè®¾ç½®ä¼˜åŒ–å™¨çš„åˆå§‹å­¦ä¹ ç‡ã€‚
  * è§£é‡Šï¼š
    * å­¦ä¹ ç‡å†³å®šäº†æ¨¡å‹åœ¨æ¯æ¬¡æ›´æ–°æƒé‡æ—¶ï¼Œå‚æ•°è°ƒæ•´çš„å¹…åº¦ã€‚
    * è¾ƒå°çš„å­¦ä¹ ç‡å¯ä»¥ä½¿è®­ç»ƒæ›´ç¨³å®šï¼Œä½†å¯èƒ½ä¼šé™ä½è®­ç»ƒé€Ÿåº¦ã€‚
    * è¾ƒå¤§çš„å­¦ä¹ ç‡å¯ä»¥åŠ é€Ÿè®­ç»ƒï¼Œä½†å¯èƒ½ä¼šå¯¼è‡´è®­ç»ƒä¸ç¨³å®šã€‚
  * ç¤ºä¾‹ï¼š
    * 3e-4 è¡¨ç¤ºå­¦ä¹ ç‡ä¸º 0.0003ã€‚

5.  **fp16=Trueï¼šæ··åˆç²¾åº¦è®­ç»ƒ**

  * ä½œç”¨ï¼šå¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ŒèŠ‚çœæ˜¾å­˜å¹¶åŠ é€Ÿè®­ç»ƒã€‚
  * è§£é‡Šï¼š
    * æ··åˆç²¾åº¦è®­ç»ƒæ˜¯æŒ‡åŒæ—¶ä½¿ç”¨ 16 ä½ï¼ˆåŠç²¾åº¦ï¼‰å’Œ 32 ä½ï¼ˆå•ç²¾åº¦ï¼‰æµ®ç‚¹æ•°ã€‚
    * 16 ä½æµ®ç‚¹æ•°å ç”¨æ›´å°‘çš„æ˜¾å­˜ï¼Œè®¡ç®—é€Ÿåº¦æ›´å¿«ã€‚
  * ç¤ºä¾‹ï¼š
    * å¦‚æœæ˜¾å­˜ä¸è¶³ï¼Œå¯ç”¨ fp16 å¯ä»¥æ˜¾è‘—å‡å°‘æ˜¾å­˜å ç”¨ã€‚

6.  **logging_steps=20ï¼šæ—¥å¿—è®°å½•é¢‘ç‡**

  * ä½œç”¨ï¼šè®¾ç½®æ¯éš”å¤šå°‘æ­¥è®°å½•ä¸€æ¬¡æ—¥å¿—ã€‚
  * è§£é‡Šï¼š
    * æ—¥å¿—åŒ…æ‹¬æŸå¤±å€¼ã€å­¦ä¹ ç‡ç­‰ä¿¡æ¯ã€‚
    * è¿™é‡Œè®¾ç½®ä¸º 20ï¼Œè¡¨ç¤ºæ¯éš” 20 æ­¥è®°å½•ä¸€æ¬¡æ—¥å¿—ã€‚
  * ç¤ºä¾‹ï¼š
    * å¦‚æœæ€»è®­ç»ƒæ­¥æ•°æ˜¯ 1000ï¼Œä¼šè®°å½• 50 æ¬¡æ—¥å¿—ï¼ˆ1000 / 20 = 50ï¼‰ã€‚

7.  **save_strategy="no"ï¼šä¿å­˜ç­–ç•¥**

  * ä½œç”¨ï¼šè®¾ç½®æ˜¯å¦ä¿å­˜ä¸­é—´æ£€æŸ¥ç‚¹ã€‚
  * è§£é‡Šï¼š
    * "no" è¡¨ç¤ºä¸ä¿å­˜ä¸­é—´æ£€æŸ¥ç‚¹ã€‚
    * å…¶ä»–é€‰é¡¹åŒ…æ‹¬ "epoch"ï¼ˆæ¯è½®ä¿å­˜ä¸€æ¬¡ï¼‰å’Œ "steps"ï¼ˆæ¯éš”ä¸€å®šæ­¥æ•°ä¿å­˜ä¸€æ¬¡ï¼‰ã€‚
  * ç¤ºä¾‹ï¼š
    * å¦‚æœè®¾ç½®ä¸º "epoch"ï¼Œæ¯è½®è®­ç»ƒç»“æŸåä¼šä¿å­˜ä¸€æ¬¡æ¨¡å‹ã€‚

8.  **report_to="none"ï¼šç¦ç”¨ç¬¬ä¸‰æ–¹æŠ¥å‘Š**

  * ä½œç”¨ï¼šç¦ç”¨ç¬¬ä¸‰æ–¹æ—¥å¿—æŠ¥å‘Šå·¥å…·ï¼ˆå¦‚ Weights & Biasesï¼‰ã€‚
  * è§£é‡Šï¼š
    * å¦‚æœä¸éœ€è¦ä½¿ç”¨ç¬¬ä¸‰æ–¹å·¥å…·è®°å½•æ—¥å¿—ï¼Œå¯ä»¥è®¾ç½®ä¸º "none"ã€‚
  * ç¤ºä¾‹ï¼š
    * å¦‚æœè®¾ç½®ä¸º "wandb"ï¼Œæ—¥å¿—ä¼šåŒæ­¥åˆ° Weights & Biases å¹³å°ã€‚

9.  **optim="adamw_torch"ï¼šä¼˜åŒ–å™¨ç±»å‹**

  * ä½œç”¨ï¼šæŒ‡å®šä¼˜åŒ–å™¨ç±»å‹ã€‚
  * è§£é‡Šï¼š
    * adamw_torch æ˜¯ä¸€ç§å¸¸ç”¨çš„ä¼˜åŒ–å™¨ï¼Œç»“åˆäº† Adam å’Œæƒé‡è¡°å‡ï¼ˆWeight Decayï¼‰ã€‚
    * é€‚åˆå¤§å¤šæ•°æ·±åº¦å­¦ä¹ ä»»åŠ¡ã€‚
  * ç¤ºä¾‹ï¼š
    * å¦‚æœè®­ç»ƒä¸ç¨³å®šï¼Œå¯ä»¥å°è¯•å…¶ä»–ä¼˜åŒ–å™¨ï¼Œå¦‚ sgd [Stochastic Gradient Descentï¼ˆéšæœºæ¢¯åº¦ä¸‹é™ï¼‰]ã€‚SGD æ˜¯ä¸€ç§ç”¨äºä¼˜åŒ–æ¨¡å‹å‚æ•°çš„ç®—æ³•ï¼Œé€šè¿‡è®¡ç®—æŸå¤±å‡½æ•°çš„æ¢¯åº¦å¹¶æ›´æ–°å‚æ•°ï¼Œä½¿æŸå¤±å‡½æ•°æœ€å°åŒ–ã€‚

10. **no_cuda=Falseï¼šå¼ºåˆ¶ä½¿ç”¨ CUDA**

  * ä½œç”¨ï¼šå¼ºåˆ¶ä½¿ç”¨ GPU è¿›è¡Œè®­ç»ƒã€‚
  * è§£é‡Šï¼š
    * no_cuda=False è¡¨ç¤ºä½¿ç”¨ GPUã€‚
    * å¦‚æœè®¾ç½®ä¸º Trueï¼Œåˆ™ä¼šä½¿ç”¨ CPUï¼ˆä¸æ¨èï¼‰ã€‚
  * ç¤ºä¾‹ï¼š
    * å¦‚æœ GPU å¯ç”¨ï¼Œæ¨¡å‹ä¼šè‡ªåŠ¨ä½¿ç”¨ GPU è¿›è¡Œè®­ç»ƒã€‚

11. **dataloader_pin_memory=Falseï¼šç¦ç”¨é”é¡µå†…å­˜**

  * ä½œç”¨ï¼šè®¾ç½®æ˜¯å¦ä½¿ç”¨é”é¡µå†…å­˜ï¼ˆPinned Memoryï¼‰åŠ é€Ÿæ•°æ®åŠ è½½ã€‚
  * è§£é‡Šï¼š
    * é”é¡µå†…å­˜å¯ä»¥æé«˜æ•°æ®åŠ è½½é€Ÿåº¦ï¼Œä½†ä¼šå ç”¨æ›´å¤šä¸»æœºå†…å­˜ã€‚
    * è¿™é‡Œè®¾ç½®ä¸º Falseï¼Œè¡¨ç¤ºç¦ç”¨é”é¡µå†…å­˜ã€‚
  * ç¤ºä¾‹ï¼š
    * å¦‚æœä¸»æœºå†…å­˜å……è¶³ï¼Œå¯ä»¥è®¾ç½®ä¸º True ä»¥åŠ é€Ÿè®­ç»ƒã€‚

12. **remove_unused_columns=Falseï¼šä¿ç•™æœªä½¿ç”¨çš„åˆ—**

  * ä½œç”¨ï¼šè®¾ç½®æ˜¯å¦ç§»é™¤æ•°æ®é›†ä¸­æœªä½¿ç”¨çš„åˆ—ã€‚
  * è§£é‡Šï¼š
    * å¦‚æœè®¾ç½®ä¸º Trueï¼Œä¼šç§»é™¤æ•°æ®é›†ä¸­æœªè¢«æ¨¡å‹ä½¿ç”¨çš„åˆ—ã€‚
    * è¿™é‡Œè®¾ç½®ä¸º Falseï¼Œè¡¨ç¤ºä¿ç•™æ‰€æœ‰åˆ—ã€‚
  * ç¤ºä¾‹ï¼š
    * å¦‚æœæ•°æ®é›†ä¸­åŒ…å«ä¸€äº›é¢å¤–çš„ä¿¡æ¯ï¼ˆå¦‚ IDï¼‰ï¼Œå¯ä»¥ä¿ç•™è¿™äº›åˆ—ã€‚

## ä¸»å‡½æ•°ï¼ˆè®­ç»ƒæµç¨‹ï¼‰

* åŠŸèƒ½æ€»ç»“ï¼šæ•´åˆæ‰€æœ‰ç»„ä»¶ï¼Œæ‰§è¡Œå®Œæ•´è®­ç»ƒæµç¨‹ã€‚

```python
def main():
    # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    os.makedirs(output_path, exist_ok=True)

    # åŠ è½½Tokenizerå¹¶è®¾ç½®å¡«å……ç¬¦
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    tokenizer.pad_token = tokenizer.eos_token  # ä½¿ç”¨EOSä½œä¸ºå¡«å……ç¬¦

    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆåŠç²¾åº¦+æŒ‡å®šGPUï¼‰
    model = AutoModelForCausalLM.from_pretrained(
        model_path,
        torch_dtype=torch.float16,       # åŠç²¾åº¦åŠ è½½ï¼ˆèŠ‚çœæ˜¾å­˜ï¼‰
        device_map={"": device}          # æŒ‡å®šä½¿ç”¨çš„GPUè®¾å¤‡
    )
    # åº”ç”¨LoRAé€‚é…å™¨
    model = get_peft_model(model, peft_config)
    model.print_trainable_parameters()   # æ‰“å°å¯è®­ç»ƒå‚æ•°é‡

    # å‡†å¤‡è®­ç»ƒæ•°æ®é›†
    dataset = process_data(tokenizer)

    # åˆå§‹åŒ–æŸå¤±è®°å½•å›è°ƒ
    loss_callback = LossCallback()

    # æ•°æ®æ•´ç†å‡½æ•°ï¼ˆæ„é€ æ‰¹æ¬¡ï¼‰
    def data_collator(data):
        batch = {
            "input_ids": torch.stack([torch.tensor(d["input_ids"]) for d in data]).to(device),
            "attention_mask": torch.stack([torch.tensor(d["attention_mask"]) for d in data]).to(device),
            "labels": torch.stack([torch.tensor(d["input_ids"]) for d in data]).to(device)  # æ ‡ç­¾=è¾“å…¥ï¼ˆå› æœLMä»»åŠ¡ï¼‰
        }
        return batch

    # åˆå§‹åŒ–Trainer
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=dataset,
        data_collator=data_collator,  # è‡ªå®šä¹‰æ•°æ®æ•´ç†
        callbacks=[loss_callback]     # æ·»åŠ å›è°ƒ
    )

    # æ‰§è¡Œè®­ç»ƒ
    print("å¼€å§‹è®­ç»ƒ...")
    trainer.train()

    # ä¿å­˜å¾®è°ƒåçš„æ¨¡å‹
    trainer.model.save_pretrained(output_path)
    print(f"æ¨¡å‹å·²ä¿å­˜è‡³ï¼š{output_path}")

    # ç»˜åˆ¶æŸå¤±æ›²çº¿
    plt.figure(figsize=(10, 6))
    plt.plot(loss_callback.losses)
    plt.title("Training Loss Curve")
    plt.xlabel("Steps")
    plt.ylabel("Loss")
    plt.savefig(os.path.join(output_path, "loss_curve.png"))  # ä¿å­˜ä¸ºPNG
    print("Lossæ›²çº¿å·²ä¿å­˜")

if __name__ == "__main__":
    main()
```
## å…³é”®ä»£ç ï¼š

1.  **åŠ è½½ Tokenizer å¹¶è®¾ç½®å¡«å……ç¬¦**

  * ä½œç”¨ï¼šåŠ è½½é¢„è®­ç»ƒæ¨¡å‹çš„åˆ†è¯å™¨ï¼Œå¹¶è®¾ç½®å¡«å……ç¬¦ã€‚
  * è§£é‡Šï¼š
    * `AutoTokenizer.from_pretrained`ï¼šè‡ªåŠ¨åŠ è½½ä¸æ¨¡å‹åŒ¹é…çš„åˆ†è¯å™¨ã€‚
    * `tokenizer.pad_token = tokenizer.eos_token`ï¼šå°†ç»“æŸç¬¦ï¼ˆEOSï¼‰ä½œä¸ºå¡«å……ç¬¦ï¼ˆPad Tokenï¼‰ã€‚
  * ç¤ºä¾‹ï¼š
    * å¦‚æœè¾“å…¥åºåˆ—é•¿åº¦ä¸è¶³ï¼Œä¼šç”¨ EOS å¡«å……ã€‚

    ```python
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    tokenizer.pad_token = tokenizer.eos_token  # ä½¿ç”¨EOSä½œä¸ºå¡«å……ç¬¦
    ```

2.  **åŠ è½½é¢„è®­ç»ƒæ¨¡å‹**

  * ä½œç”¨ï¼šåŠ è½½é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ï¼Œå¹¶é…ç½®ç¡¬ä»¶ç›¸å…³è®¾ç½®ã€‚
  * è§£é‡Šï¼š
    * `AutoModelForCausalLM.from_pretrained`ï¼šåŠ è½½å› æœè¯­è¨€æ¨¡å‹ï¼ˆå¦‚ GPTï¼‰ã€‚
    * `torch_dtype=torch.float16`ï¼šä½¿ç”¨åŠç²¾åº¦ï¼ˆ16 ä½æµ®ç‚¹æ•°ï¼‰åŠ è½½æ¨¡å‹ï¼ŒèŠ‚çœæ˜¾å­˜ã€‚
    * `device_map={"": device}`ï¼šå°†æ¨¡å‹åŠ è½½åˆ°æŒ‡å®šçš„ GPU è®¾å¤‡ä¸Šã€‚
  * ç¤ºä¾‹ï¼š
    * å¦‚æœ `device = "cuda:0"`ï¼Œæ¨¡å‹ä¼šåŠ è½½åˆ°ç¬¬ä¸€ä¸ª GPU ä¸Šã€‚

    ```python
    model = AutoModelForCausalLM.from_pretrained(
        model_path,
        torch_dtype=torch.float16,       # åŠç²¾åº¦åŠ è½½ï¼ˆèŠ‚çœæ˜¾å­˜ï¼‰
        device_map={"": device}          # æŒ‡å®šä½¿ç”¨çš„GPUè®¾å¤‡
    )
    ```

3.  **æ•°æ®æ•´ç†å‡½æ•°**

  * ä½œç”¨ï¼šå°†å¤šæ¡æ•°æ®æ•´ç†æˆä¸€ä¸ªæ‰¹æ¬¡ã€‚
  * è§£é‡Šï¼š
    * `input_ids`ï¼šè¾“å…¥åºåˆ—çš„ token IDã€‚
    * `attention_mask`ï¼šæ ‡è®°æœ‰æ•ˆ token çš„ä½ç½®ã€‚
    * `labels`ï¼šå› æœè¯­è¨€æ¨¡å‹çš„æ ‡ç­¾ä¸è¾“å…¥ç›¸åŒï¼ˆæ¨¡å‹éœ€è¦é¢„æµ‹ä¸‹ä¸€ä¸ª tokenï¼‰ã€‚
  * ç¤ºä¾‹ï¼š
    * å¦‚æœè¾“å…¥æ˜¯ `["è¯Šæ–­é—®é¢˜ï¼šå‘çƒ§æ€ä¹ˆåŠï¼Ÿ", "è¯Šæ–­é—®é¢˜ï¼šå¤´ç—›æ€ä¹ˆåŠï¼Ÿ"]`ï¼Œä¼šè¢«æ•´ç†æˆä¸€ä¸ªæ‰¹æ¬¡ã€‚

    ```python
    def data_collator(data):
        batch = {
            "input_ids": torch.stack([torch.tensor(d["input_ids"]) for d in data]).to(device),
            "attention_mask": torch.stack([torch.tensor(d["attention_mask"]) for d in data]).to(device),
            "labels": torch.stack([torch.tensor(d["input_ids"]) for d in data]).to(device)  # æ ‡ç­¾=è¾“å…¥ï¼ˆå› æœLMä»»åŠ¡ï¼‰
        }
        return batch
    ```

4.  **åˆå§‹åŒ– Trainer**

  * ä½œç”¨ï¼šåˆ›å»ºè®­ç»ƒå™¨å¯¹è±¡ï¼Œç®¡ç†è®­ç»ƒè¿‡ç¨‹ã€‚
  * è§£é‡Šï¼š
    * `model`ï¼šè¦è®­ç»ƒçš„æ¨¡å‹ã€‚
    * `args`ï¼šè®­ç»ƒå‚æ•°ï¼ˆå¦‚æ‰¹æ¬¡å¤§å°ã€å­¦ä¹ ç‡ç­‰ï¼‰ã€‚
    * `train_dataset`ï¼šè®­ç»ƒæ•°æ®é›†ã€‚
    * `data_collator`ï¼šè‡ªå®šä¹‰çš„æ•°æ®æ•´ç†å‡½æ•°ã€‚
    * `callbacks`ï¼šè®­ç»ƒå›è°ƒï¼ˆå¦‚æŸå¤±è®°å½•ï¼‰ã€‚

    ```python
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=dataset,
        data_collator=data_collator,  # è‡ªå®šä¹‰æ•°æ®æ•´ç†
        callbacks=[loss_callback]     # æ·»åŠ å›è°ƒ
    )
    ```

## å››ã€å®Œç»“æ„Ÿè¨€

éå¸¸æ„Ÿè°¢ Deepseek å®˜ç½‘æ»¡è¡€ç‰ˆåœ¨æœ¬ç« çš„ä»£ç ä¿®æ”¹ã€èµ„æ–™æ”¶é›†ä»¥åŠæ–‡ç« æ¶¦è‰²æ–¹é¢æä¾›çš„å®è´µå¸®åŠ©ï¼

æœ¬ç« çš„å¾®è°ƒéƒ¨åˆ†ç›®å‰è¿˜è¾ƒä¸ºåŸºç¡€ï¼Œå¯¼è‡´æŸå¤±å‡½æ•°çš„æ”¶æ•›æ•ˆæœä¸å¤Ÿç†æƒ³ï¼Œä»æœ‰è¾ƒå¤§çš„ä¼˜åŒ–ç©ºé—´ã€‚ä¾‹å¦‚ï¼Œæ•°æ®é›†æ„å»ºå¯ä»¥æ›´åŠ ç²¾ç»†åŒ–ï¼Œä»£ç ç»“æ„ä¹Ÿæœ‰å¾…è¿›ä¸€æ­¥ä¼˜åŒ–å’Œè°ƒæ•´ã€‚æˆ‘ä»¬éå¸¸æœŸå¾…å„ä½å°ä¼™ä¼´çš„å®è´µå»ºè®®å’ŒæŒ‡æ­£ï¼Œè®©æˆ‘ä»¬å…±åŒè¿›æ­¥ï¼Œä¸€èµ·åœ¨ AI å­¦ä¹ çš„é“è·¯ä¸Šæ¢ç´¢æ›´å¤šä¹è¶£ï¼

> æ–‡ç« æ¥æºï¼šåŸåˆ› å´é”¦å‡¤ Datawhale https://mp.weixin.qq.com/s/hOgeu6EPbuaQgVHyjij-kg 



